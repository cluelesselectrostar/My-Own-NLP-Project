{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597720843099",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "> Data cleaning helps avoid \"garbage in , garbage out\" -- we do not want to feed meaningless data into a model which will probably return us with more meaningless junk.\n",
    "\n",
    "This time I will skip the scraping part that data scientists normally do. This allows the content to be updated over time, but to be fair the content is pretty static anyways so I don't really see the point of doing so. In addition, I imagine there would be quite a number of problems if the layout of the site changes.\n",
    "\n",
    "## Outline for data cleaning\n",
    "- Input: a simple text file with metadata removed. Headers and page numbers are kept though.\n",
    "- Common Pre-processing/ cleaning procedures\n",
    "  - All lower case\n",
    "  - Remove punctuation, symbols and numerical values\n",
    "  - Remove common non-sensical text (such as line breakers `\\n`)\n",
    "  - Tokenize text: split sentences into individual words (in preparation for DTM)\n",
    "  - Remove stop-words\n",
    "  - Using NLTK perform stemming and lemmatisation for words in the DTM, to reduce the number of inflicted words.\n",
    "  - Parts of speech tagging\n",
    "  - DTM for bi-grams/ tri-grams (phrases like thank you)\n",
    "- Output\n",
    "  - Corpus: not much different from the actual input since there is only one file here....... but with all the data cleaned up.\n",
    "  - Document Term matrix: a matrix of word counts in the entire corpus.\n",
    "\n",
    "SpaCy can also perform these NLTK techniques as well, with a greater degree of efficiency. The extra features might be overkill for the time being though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "\n",
    "For the purposes of this project, I will simply import the data from a text file, which will be parsed into a string object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of file names for books to be analysed.\n",
    "filenames = [\n",
    "    'books/charlieandthechocolatefactory.txt',\n",
    "    'books/fantasticmrfox.txt',\n",
    "    'books/matilda.txt'\n",
    "]\n",
    "\n",
    "bookNames = [\n",
    "    'chocofact',\n",
    "    'fox',\n",
    "    'matilda'\n",
    "]\n",
    "\n",
    "fullNames = [\n",
    "    'Charlie and the Chocolate Factory',\n",
    "    'Fantastic Mr Fox!',\n",
    "    'Matilda'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import text files and remove non sensical '\\n'\n",
    "def importText(fileName):\n",
    "    data = open(fileName, \"r\", encoding=\"utf-8\").read().replace('\\n', ' ')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The Reader of Books    It’s a funny thing about mothers and fathers. Even  when their own child is the most disgusting little blister  you could ever imagine, they still think that he or she is  wonderful.   Some parents go further. They become so blinded by  adoration they manage to convince themselves their  child has qualities of genius.   Well, there is nothing very wrong with all this. It’s the  way of the world. It is only when the parents begin  telling us about the brilliance of their own revolting off¬  spring, that we start shouting, 'Bring us a basin! We’re  going to be sick!’    3      School teachers suffer a good deal from having to  listen to this sort of twaddle from proud parents, but  they usually get their own back when the time comes  to write the end-of-term reports. If I were a teacher I  would cook up some real scorchers for the children of  doting parents. ‘Your son Maximilian,’ I would write,  ‘is a total wash-out. I hope you have a family business  you can push him into when he leaves school because  he sure as heck won’t get a job anywhere else.’ Or if I  were feeling lyrical that day, 1 might write, ‘It is a  curious truth that grasshoppers have their hearing-  organs in the sides of the abdomen. Your daughter  Vanessa, judging by what she’s learnt this term, has no  hearing-organs at all.’    4          I might even delve deeper into natural history and  say, ‘The periodical cicada spends six years as a grub  underground, and no more than six days as a free  creature of sunlight and air. Your son Wilfred has spent  six years as a grub in this school and we are still  waiting for him to emerge from the chrysalis. 5 A  particularly poisonous little girl might sting me into  saying, ‘Fiona has the same glacial beauty as an  iceberg, but unlike the iceberg she has absolutely     nothing below the surface. 5 I think I might enjoy  writing end-of-term reports for the stinkers in my class.  But enough of that. We have to get on.    5          Occasionally one conies across parents who take the  opposite line, who show no interest at all in their  children, and these of course are far worse than the  doting ones. Mr and Mrs Wormwood were two such  parents. They had a son called Michael and a  1 /> daughter called Matilda, and the parents  . , O looked upon Matilda in particular as  Of ^ ^ K, nothin? more than a scab. A scab is some-  Vas A thing you have to put up with until the  time comes when you can pick it off and flick  it away. Mr and Mrs Wormwood looked forward  enormously to the time when they could pick  their little daughter off and flick her away,  preferably into the next county 7 or even further  than that.   It is bad enough when parents treat ordinary  children as though they were scabs and bunions, but it  becomes somehow a lot worse when the child  in question is extra- ordinary, and by that I  mean sensitive and brilliant. Matilda was  both of these things, but above all she was  brilliant. Her mind was so\n"
    }
   ],
   "source": [
    "# Test print the first 5000 characters of the third book 'Matilda'\n",
    "rawBooks = [importText(bkName) for bkName in filenames]\n",
    "print(rawBooks[2][:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to make sure that the texts are indexed with their names as well, such that we don't necessarily have to access them with a specific number. This makes it way more convenient the access the data in the future, especially if we decide to append a few more copies of Roald Dahl's texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                   full_names  \\\nbook_names                                      \nchocofact   Charlie and the Chocolate Factory   \nfox                         Fantastic Mr Fox!   \nmatilda                               Matilda   \n\n                                                                                                                                                             text  \nbook_names                                                                                                                                                         \nchocofact   This book is fantastic it is about a very poor boy named Charlie Bucket. He always  goes to school with out a jacket because they don’t have money...  \nfox         Down in the valley there were three farms. The owners of these farms had done well. They were rich men. They were also nasty men. All three of the...  \nmatilda      The Reader of Books    It’s a funny thing about mothers and fathers. Even  when their own child is the most disgusting little blister  you could ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_names</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>book_names</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>chocofact</th>\n      <td>Charlie and the Chocolate Factory</td>\n      <td>This book is fantastic it is about a very poor boy named Charlie Bucket. He always  goes to school with out a jacket because they don’t have money...</td>\n    </tr>\n    <tr>\n      <th>fox</th>\n      <td>Fantastic Mr Fox!</td>\n      <td>Down in the valley there were three farms. The owners of these farms had done well. They were rich men. They were also nasty men. All three of the...</td>\n    </tr>\n    <tr>\n      <th>matilda</th>\n      <td>Matilda</td>\n      <td>The Reader of Books    It’s a funny thing about mothers and fathers. Even  when their own child is the most disgusting little blister  you could ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "raw_df = pd.DataFrame({'book_names':bookNames, 'full_names': fullNames, 'text':rawBooks})\n",
    "\n",
    "# set book names as index\n",
    "raw_df = raw_df.set_index('book_names')\n",
    "\n",
    "# sort dataframe and print\n",
    "raw_df = raw_df.sort_index()\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed any further, we should also pickle a raw copy of all books, which saves the object in a binary format. This is done for contingency purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"rawBooks.pkl\", \"wb\") as file:\n",
    "    pickle.dump(raw_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method NDFrame.keys of                                    full_names  \\\nbook_names                                      \nchocofact   Charlie and the Chocolate Factory   \nfox                         Fantastic Mr Fox!   \nmatilda                               Matilda   \n\n                                                                                                                                                             text  \nbook_names                                                                                                                                                         \nchocofact   This book is fantastic it is about a very poor boy named Charlie Bucket. He always  goes to school with out a jacket because they don’t have money...  \nfox         Down in the valley there were three farms. The owners of these farms had done well. They were rich men. They were also nasty men. All three of the...  \nmatilda      The Reader of Books    It’s a funny thing about mothers and fathers. Even  when their own child is the most disgusting little blister  you could ...  >"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Check the list of book names (keys)\n",
    "raw_df.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' cider inside her inside.’  Then Badger joined in: 48  \\x0c‘Oh poor Mrs Badger, he cried, So hungry she very near died. But she’ll not feel so hollow If only she’ll swallow Some cider inside her inside.’  They were still singing as they rounded the final corner and burst in upon the most wonderful and amazing sight any of them had ever seen. The feast was just beginning. A large dining-room had been hollowed out of the earth, and in the middle of it, seated around a huge table, were no less than twenty-nine animals. They were: Mrs Fox and three Small Foxes. Mrs Badger and three Small Badgers. Mole and Mrs Mole and four Small Moles. Rabbit and Mrs Rabbit and five Small Rabbits. 49  \\x0cWeasel and Mrs Weasel and six Small Weasels. The table was covered with chickens and ducks and geese and hams and bacon, and everyone was tucking into the lovely food. ‘My darling!’ cried Mrs Fox, jumping up and hugging Mr Fox. ‘We couldn’t wait! Please forgive us!’ Then she hugged the Smallest Fox of all, and Mrs Badger hugged Badger, and everyone hugged everyone else. Amid shouts of joy, the great jars of cider were placed upon the table, and Mr Fox and Badger and the Smallest Fox sat down with the others. You must remember no one had eaten a thing for several days. They were ravenous. So for a while there was no conversation at all. There was only the sound of crunching and chewing as the animals attacked the succulent food. At last, Badger stood up. He raised his glass of cider and called out, ‘A toast! I want you all to stand and drink a toast to our dear friend who has saved our lives this day – Mr Fox!’ ‘To Mr Fox!’ they all shouted, standing up and raising their glasses. ‘To Mr Fox! Long may he live!’ Then Mrs Fox got shyly to her feet and said, ‘I don’t want to make a speech. I just want to say one thing, and it is this: MY HUSBAND IS A FANTASTIC FOX.’ 50  \\x0cEveryone clapped and cheered. Then Mr Fox himself stood up. ‘This delicious meal . . .’ he began, then he stopped. In the silence that followed, he let fly a tremendous belch. There was laughter and more clapping. ‘This delicious meal, my friends,’ he went on, ‘is by courtesy of Messrs Boggis, Bunce and Bean.’ (More cheering and laughter.) ‘And I hope you have enjoyed it as much as I have.’ He let fly another colossal belch. ‘Better out than in,’ said Badger. ‘Thank you,’ said Mr Fox, grinning hugely. ‘But now, my friends, let us be serious. Let us think of tomorrow and the next day and the days after that. If we go out, we will be killed. Right?’ ‘Right!’ they shouted. ‘We’ll be shot before we’ve gone a yard,’ said Badger. ‘Ex-actly,’ said Mr Fox. ‘But whowants to go out, anyway; let me ask you that? We are all diggers, every one of us. We hate the outside. The outside is full of enemies. We only go out because we have to, to get food for our families. But now, my friends, we have an entirely new set-up. We have a safe tunnel leading to three of the finest stores in the world!’ ‘We do indeed!’ said Badger. ‘I’ve seen ’em!’ 51  \\x0c‘And you know what this means?’ said Mr Fox. ‘It means that none of us need ever go out into the open again!’ There was a buzz of excitement around the table. ‘I therefore invite you all,’ Mr Fox went on, ‘to stay here with me for ever.’ ‘For ever!’ they cried. ‘My goodness! How marvellous!’ And Rabbit said to Mrs Rabbit, ‘My dear, just think! We’re never going to be shot at again in our lives!’ ‘We will make,’ said Mr Fox, ‘a little underground village, with streets and houses on each side – separate houses for Badgers and Moles and Rabbits and Weasels and Foxes. And every day I will go shopping for you all. And every day we will eat like kings.’ The cheering that followed this speech went on for many minutes.  52  \\x0cOutside the fox’s hole, Boggis and Bunce and Bean sat beside their tents with their guns on their laps. It was beginning to rain. Water was trickling down the necks of the three men and into their shoes. ‘He won’t stay down there much longer now,’ Boggis said. ‘The brute must be famished,’ Bunce said. ‘That’s right,’ Bean said. ‘He’ll be making a dash for it any moment. Keep your guns handy.’ They sat there by the hole, waiting for the fox to come out. And so far as I know, they are still waiting.  53  \\x0c'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Test print the contents for Fantastic Mr Fox!\n",
    "raw_df.text.loc['fox'][47000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Data cleaning!\n",
    "\n",
    "When data scientists process numerical data, they often remove invalid data (which can be automatically and manually interpreted), duplicate data, outliers and null data. There are several methods that we can iteratively apply along the way to clean our data:\n",
    "  - All lower case\n",
    "  - Remove punctuation, symbols and numerical values\n",
    "  - Remove common non-sensical text (such as line breakers `\\n`, as well as other escape characters such as `51\\x0c`)\n",
    "  - Tokenize text: split sentences into individual words (in preparation for DTM)\n",
    "  - Remove stop-words\n",
    "  - Using NLTK perform stemming and lemmatisation for words in the DTM, to reduce the number of inflicted words.\n",
    "  - Parts of speech tagging\n",
    "  - DTM for bi-grams/ tri-grams (phrases like thank you)\n",
    "  - fix typos (a bit too advanced.......)\n",
    "\n",
    "We want to apply these methods iteratively such that we can observe the results after each cleaning stage; this is especially important for text-preprocessing since an overly aggressive approach may result in key information being lost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make all text lower case, get rid of punctuation, numbers and other non-sensical text.\n",
    "\n",
    "# Packages for string manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "def basic_text_clean(text):\n",
    "    text = text.lower() #lower case\n",
    "    text = re.sub('\\x0c', ' ', text) # non sensical text\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text) # punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text) # numbers in between text\n",
    "    return text\n",
    "\n",
    "basic_cleaning = lambda x: basic_text_clean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some say quotes (so things within single or double quotation marks) should be removed as well, but in this context, I believe dialogues or conversations within the story are pretty important as well, so might as well see how things work out first......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                                                                                                                             text\nbook_names                                                                                                                                                       \nchocofact   this book is fantastic it is about a very poor boy named charlie bucket  he always  goes to school with out a jacket because they don’t have money...\nfox         down in the valley there were three farms  the owners of these farms had done well  they were rich men  they were also nasty men  all three of the...\nmatilda      the reader of books    it’s a funny thing about mothers and fathers  even  when their own child is the most disgusting little blister  you could ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>book_names</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>chocofact</th>\n      <td>this book is fantastic it is about a very poor boy named charlie bucket  he always  goes to school with out a jacket because they don’t have money...</td>\n    </tr>\n    <tr>\n      <th>fox</th>\n      <td>down in the valley there were three farms  the owners of these farms had done well  they were rich men  they were also nasty men  all three of the...</td>\n    </tr>\n    <tr>\n      <th>matilda</th>\n      <td>the reader of books    it’s a funny thing about mothers and fathers  even  when their own child is the most disgusting little blister  you could ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data_b_cleaned = pd.DataFrame(raw_df.text.apply(basic_cleaning))\n",
    "data_b_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'r joined in      ‘oh poor mrs badger  he cried  so hungry she very near died  but she’ll not feel so hollow if only she’ll swallow some cider inside her inside ’  they were still singing as they rounded the final corner and burst in upon the most wonderful and amazing sight any of them had ever seen  the feast was just beginning  a large dining room had been hollowed out of the earth  and in the middle of it  seated around a huge table  were no less than twenty nine animals  they were  mrs fox and three small foxes  mrs badger and three small badgers  mole and mrs mole and four small moles  rabbit and mrs rabbit and five small rabbits      weasel and mrs weasel and six small weasels  the table was covered with chickens and ducks and geese and hams and bacon  and everyone was tucking into the lovely food  ‘my darling ’ cried mrs fox  jumping up and hugging mr fox  ‘we couldn’t wait  please forgive us ’ then she hugged the smallest fox of all  and mrs badger hugged badger  and everyone hugged everyone else  amid shouts of joy  the great jars of cider were placed upon the table  and mr fox and badger and the smallest fox sat down with the others  you must remember no one had eaten a thing for several days  they were ravenous  so for a while there was no conversation at all  there was only the sound of crunching and chewing as the animals attacked the succulent food  at last  badger stood up  he raised his glass of cider and called out  ‘a toast  i want you all to stand and drink a toast to our dear friend who has saved our lives this day – mr fox ’ ‘to mr fox ’ they all shouted  standing up and raising their glasses  ‘to mr fox  long may he live ’ then mrs fox got shyly to her feet and said  ‘i don’t want to make a speech  i just want to say one thing  and it is this  my husband is a fantastic fox ’     everyone clapped and cheered  then mr fox himself stood up  ‘this delicious meal      ’ he began  then he stopped  in the silence that followed  he let fly a tremendous belch  there was laughter and more clapping  ‘this delicious meal  my friends ’ he went on  ‘is by courtesy of messrs boggis  bunce and bean ’  more cheering and laughter   ‘and i hope you have enjoyed it as much as i have ’ he let fly another colossal belch  ‘better out than in ’ said badger  ‘thank you ’ said mr fox  grinning hugely  ‘but now  my friends  let us be serious  let us think of tomorrow and the next day and the days after that  if we go out  we will be killed  right ’ ‘right ’ they shouted  ‘we’ll be shot before we’ve gone a yard ’ said badger  ‘ex actly ’ said mr fox  ‘but whowants to go out  anyway  let me ask you that  we are all diggers  every one of us  we hate the outside  the outside is full of enemies  we only go out because we have to  to get food for our families  but now  my friends  we have an entirely new set up  we have a safe tunnel leading to three of the finest stores in the world ’ ‘we do indeed ’ said badger  ‘i’ve seen ’em ’     ‘and you know what this means ’ said mr fox  ‘it means that none of us need ever go out into the open again ’ there was a buzz of excitement around the table  ‘i therefore invite you all ’ mr fox went on  ‘to stay here with me for ever ’ ‘for ever ’ they cried  ‘my goodness  how marvellous ’ and rabbit said to mrs rabbit  ‘my dear  just think  we’re never going to be shot at again in our lives ’ ‘we will make ’ said mr fox  ‘a little underground village  with streets and houses on each side – separate houses for badgers and moles and rabbits and weasels and foxes  and every day i will go shopping for you all  and every day we will eat like kings ’ the cheering that followed this speech went on for many minutes       outside the fox’s hole  boggis and bunce and bean sat beside their tents with their guns on their laps  it was beginning to rain  water was trickling down the necks of the three men and into their shoes  ‘he won’t stay down there much longer now ’ boggis said  ‘the brute must be famished ’ bunce said  ‘that’s right ’ bean said  ‘he’ll be making a dash for it any moment  keep your guns handy ’ they sat there by the hole  waiting for the fox to come out  and so far as i know  they are still waiting       '"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data_b_cleaned.text.loc['fox'][47000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corppus cleaned!\n",
    "\n",
    "As we can see, not much has actually been done so far, but at this point, at least the text makes sense. Since the actual order of words do matter for things like sentiment analysis, performing further cleaning techniques such as stemming and lemmatisation will only worsen the final sentence generation algorithm. So at this point, the corpus is ready to be pickled for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b_cleaned.to_pickle(\"basic_cleaned_corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Term Matrix (DTM)\n",
    "\n",
    "### Tokenization and Stop Words\n",
    "\n",
    "A DTM is a database of words within various documents. This means the text is split into words (tokenization) for further analysis. In this sceario, we can apply further techqniques to remove relatively meaningless words, such as 'a', 'the' or other various prepositions.  These are known as stop words.\n",
    "\n",
    "The pakages that we can utilise for this section are:\n",
    "- scikit-learn's CountVectorizer\n",
    "- NLTK\n",
    "- (maybe) SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            aback  abandon  abc  abdomen  abide  abilities  ability  able  \\\nbook_names                                                                  \nchocofact       0        0    0        0      1          0        0    13   \nfox             0        0    0        0      0          0        0     0   \nmatilda         1        1    1        1      0          1        3    14   \n\n            absolute  absolutely  ...  yippeeeeee  yippeeeeeeee  \\\nbook_names                        ...                             \nchocofact          2          10  ...           1             1   \nfox                0           1  ...           0             0   \nmatilda            5           6  ...           0             0   \n\n            yippeeeeeeeeee  youheard  young  younger  youreally  youth  zing  \\\nbook_names                                                                     \nchocofact                1         0      6        1          0      1     1   \nfox                      0         1      1        0          1      0     0   \nmatilda                  0         0     14        1          0      0     0   \n\n            zip  \nbook_names       \nchocofact     1  \nfox           0  \nmatilda       0  \n\n[3 rows x 5712 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aback</th>\n      <th>abandon</th>\n      <th>abc</th>\n      <th>abdomen</th>\n      <th>abide</th>\n      <th>abilities</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absolute</th>\n      <th>absolutely</th>\n      <th>...</th>\n      <th>yippeeeeee</th>\n      <th>yippeeeeeeee</th>\n      <th>yippeeeeeeeeee</th>\n      <th>youheard</th>\n      <th>young</th>\n      <th>younger</th>\n      <th>youreally</th>\n      <th>youth</th>\n      <th>zing</th>\n      <th>zip</th>\n    </tr>\n    <tr>\n      <th>book_names</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>chocofact</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>2</td>\n      <td>10</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>fox</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>matilda</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>14</td>\n      <td>5</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 5712 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Tokenize text, fit it into a mask (that removes stop words), and transform it in a DTM\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_b_cleaned.text) \n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names()) #Transform DTM (in context a vocabulary/ dictionary) into pandas dataframe format\n",
    "data_dtm.index = data_b_cleaned.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of this format are immediately apparent. It allows us to filter some meaningless words and presents the data in a neat and organised manner. Let's pickle this relatively raw or primitive DTM first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm.to_pickle(\"data_dtm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams\n",
    "\n",
    "Dealing with an excessively large dataset is messy for various reasons:\n",
    "- As we can see, there are some really similar words like \"young\" or \"younger\", which are stemmings or lemmatisations from a \"root word\"\n",
    "- Some words that have arbitrary spelling like \"yippeeeeeeee....!\"\n",
    "- Some frequency for certain words are quite low, which means that they won't really be used for things like topic analysis occurs. Perhaps they should be removed as well!\n",
    "\n",
    "To recall, these are the things that we can work on to further clean our data:\n",
    "  - Perform stemming and lemmatisation for words in the DTM, to reduce the number of inflicted words.\n",
    "  - Parts of speech tagging\n",
    "  - Collating bi-grams/ tri-grams (phrases like thank you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            aback  aback arrival  abandon  abandon trunchbull  abc  abc quite  \\\nbook_names                                                                      \nchocofact       0              0        0                   0    0          0   \nfox             0              0        0                   0    0          0   \nmatilda         1              1        1                   1    1          1   \n\n            abdomen  abdomen daughter  abide  abide ugliness  ...  \\\nbook_names                                                    ...   \nchocofact         0                 0      1               1  ...   \nfox               0                 0      0               0  ...   \nmatilda           1                 1      0               0  ...   \n\n            younger children  younger ones  youreally  youreally mean  youth  \\\nbook_names                                                                     \nchocofact                  0             1          0               0      1   \nfox                        0             0          1               1      0   \nmatilda                    1             0          0               0      0   \n\n            youth just  zing  zing fantastic  zip  zip guns  \nbook_names                                                   \nchocofact            1     1               1    1         1  \nfox                  0     0               0    0         0  \nmatilda              0     0               0    0         0  \n\n[3 rows x 35177 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aback</th>\n      <th>aback arrival</th>\n      <th>abandon</th>\n      <th>abandon trunchbull</th>\n      <th>abc</th>\n      <th>abc quite</th>\n      <th>abdomen</th>\n      <th>abdomen daughter</th>\n      <th>abide</th>\n      <th>abide ugliness</th>\n      <th>...</th>\n      <th>younger children</th>\n      <th>younger ones</th>\n      <th>youreally</th>\n      <th>youreally mean</th>\n      <th>youth</th>\n      <th>youth just</th>\n      <th>zing</th>\n      <th>zing fantastic</th>\n      <th>zip</th>\n      <th>zip guns</th>\n    </tr>\n    <tr>\n      <th>book_names</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>chocofact</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>fox</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>matilda</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 35177 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Accept bigrams as well\n",
    "bigrams_cv = CountVectorizer(stop_words='english', ngram_range= (1,2)) \n",
    "cleaned_cv = bigrams_cv.fit_transform(data_b_cleaned.text) \n",
    "cleaned_data_dtm = pd.DataFrame(cleaned_cv.toarray(), columns=bigrams_cv.get_feature_names())\n",
    "cleaned_data_dtm.index = data_dtm.index\n",
    "cleaned_data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look very useful now since there are 35000 columns! Let's only keep words that have appeared more than 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "book_names          chocofact  fox  matilda  sum\naback                       0    0        1    1\naback arrival               0    0        1    1\nabandon                     0    0        1    1\nabandon trunchbull          0    0        1    1\nabc                         0    0        1    1\n...                       ...  ...      ...  ...\nyouth just                  1    0        0    1\nzing                        1    0        0    1\nzing fantastic              1    0        0    1\nzip                         1    0        0    1\nzip guns                    1    0        0    1\n\n[35177 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>book_names</th>\n      <th>chocofact</th>\n      <th>fox</th>\n      <th>matilda</th>\n      <th>sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>aback</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>aback arrival</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>abandon</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>abandon trunchbull</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>abc</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>youth just</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>zing</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>zing fantastic</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>zip</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>zip guns</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>35177 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Transpose for easier calculations, and add a column for number for sum of word frequencies in all books.\n",
    "cleaned_data_dtm = cleaned_data_dtm.transpose()\n",
    "cleaned_data_dtm['sum'] = cleaned_data_dtm.sum(axis = 1, skipna = True) \n",
    "cleaned_data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            able  absolute  absolutely  actually  added  afraid  afternoon  \\\nbook_names                                                                   \nchocofact     13         2          10         5      3       3          2   \nfox            0         0           1         1      0       0          1   \nmatilda       14         5           6         9      9       8         15   \nsum           27         7          17        15     12      11         18   \n\n            afternoons  age  ago  ...  year old  years  yelled  yelled mrs  \\\nbook_names                        ...                                        \nchocofact            0    0    2  ...         2      8      14           7   \nfox                  0    0    0  ...         0      0       4           0   \nmatilda              9    8    7  ...        11     23      13           0   \nsum                  9    8    9  ...        13     31      31           7   \n\n            yelling  yellow  yes  yes miss  yesterday  young  \nbook_names                                                    \nchocofact         3       3   29         0          2      6  \nfox               0       0   11         0          1      1  \nmatilda           4       4   37        15          6     14  \nsum               7       7   77        15          9     21  \n\n[4 rows x 1361 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>absolute</th>\n      <th>absolutely</th>\n      <th>actually</th>\n      <th>added</th>\n      <th>afraid</th>\n      <th>afternoon</th>\n      <th>afternoons</th>\n      <th>age</th>\n      <th>ago</th>\n      <th>...</th>\n      <th>year old</th>\n      <th>years</th>\n      <th>yelled</th>\n      <th>yelled mrs</th>\n      <th>yelling</th>\n      <th>yellow</th>\n      <th>yes</th>\n      <th>yes miss</th>\n      <th>yesterday</th>\n      <th>young</th>\n    </tr>\n    <tr>\n      <th>book_names</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>chocofact</th>\n      <td>13</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2</td>\n      <td>8</td>\n      <td>14</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>29</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>fox</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>matilda</th>\n      <td>14</td>\n      <td>5</td>\n      <td>6</td>\n      <td>9</td>\n      <td>9</td>\n      <td>8</td>\n      <td>15</td>\n      <td>9</td>\n      <td>8</td>\n      <td>7</td>\n      <td>...</td>\n      <td>11</td>\n      <td>23</td>\n      <td>13</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>37</td>\n      <td>15</td>\n      <td>6</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>sum</th>\n      <td>27</td>\n      <td>7</td>\n      <td>17</td>\n      <td>15</td>\n      <td>12</td>\n      <td>11</td>\n      <td>18</td>\n      <td>9</td>\n      <td>8</td>\n      <td>9</td>\n      <td>...</td>\n      <td>13</td>\n      <td>31</td>\n      <td>31</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>77</td>\n      <td>15</td>\n      <td>9</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 1361 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Only keep words that have appeared more than 5 times.\n",
    "filtered_data_dtm = cleaned_data_dtm[cleaned_data_dtm['sum'] > 5]\n",
    "\n",
    "#Transpose back to the original format and display the DTM!\n",
    "filtered_data_dtm = filtered_data_dtm.transpose()\n",
    "filtered_data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields us with a much more manageable 1361 entries. Before we proceed any furher, we should again pickle it for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm.to_pickle(\"high_bigram_dtm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "When a language contains words that are derived from another (root) word , the changes are called **inflected Language**. For example, modifications are made to reflect tense, case, aspect, person, number, gender and mood or position in speech. For example, googling fish (I use DuckDuckGo) will also result in fishes, fishing as fish is the stem of both words.\n",
    "\n",
    "Next we will utilise NLTK to perform stemming and lemmatisation for words in the DTM, to reduce the number of inflicted words.\n",
    "\n",
    "> Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language.\n",
    "\n",
    "A stem (or root) is the part of the word to which you add inflectional affixes such as (-ed,-ize, -s,-de,mis). They are obtained by removing the inflections used with a word. \n",
    "\n",
    "I love stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Using the GUI select the punkt model for download.\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}